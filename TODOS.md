# TODOS

## Phase 0: The basic look

 - [x] Flask backend, Vue.js frontend
 - [x] Front end displays the chatbot as the central UI element
 - [x] Look and feel is warm and reflective of old beautiful libraries

## Phase 1: Dummy Agent

 - [x] Add PostGreSQL Database contains a list of 10 questions
 - [x] Chatbot always asks the same list of 10 questions in the same order everytime
 - [x] At the end of the 10 questions, the entire conversation log is saved in the back end.
 - [x] A search prompt is created.
 - [x] Set up a Google Books API.
 - [x] Search prompt fed into Google Books API. 
 - [x] The search results are displayed back to the user as a grid of book cover images on a bookshelf.
 - [x] Users can click on each book cover image to expand and show title, author, and synopsis.
 - [x] UI: Chatbot interface occupies 60% of the screen width
 - [x] UI: Book recomendations occupies 60% of the screen width
 - [x] UI: Book recomendations should be on a separate page

## Phase 2: LangChain and RAG

 - [ ] Switch out the PostGreSQL database of questions with questions generated by an LLM
 - [ ] Use RAG instead of a "dummy conversation search" to find good book recommendations
 - [ ] When users can click on each book cover image to expand and show title, author, and synopsis, the chatbot also explains its rationale for recommending, tying it back to either what users said in the prior conversation or quoting the book text.
 - [ ] Fine tune the LLM using a dataset of full-text books (Project Gutenberg) so that the LLM has technically "read" all the books and can perform very good quote search and analysis to match to the user's preferences for writing style, story content, etc.